{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ed858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install CPU TensorFlow + deps (uncomment if needed)\n",
    "# %pip install -q tensorflow-cpu==2.15.0 keras==2.15.0 tensorflow-io-gcs-filesystem==0.31.0 \\\n",
    "#                 pillow matplotlib seaborn scikit-learn opencv-python\n",
    "import sys, platform, os, json\n",
    "from pathlib import Path\n",
    "print('Python:', sys.version)\n",
    "print('Platform:', platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db371c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve project paths (robust to where the notebook is opened)\n",
    "from pathlib import Path\n",
    "def find_ml_service_root(start: Path) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(10):\n",
    "        if (p / 'ml_service').exists():\n",
    "            return (p / 'ml_service')\n",
    "        if p.name == 'ml_service':\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "cwd = Path.cwd()\n",
    "ml_root = find_ml_service_root(cwd)\n",
    "print('ml_root =', ml_root)\n",
    "data_root = ml_root / 'dataset' / 'Autism emotion recogition dataset' / 'Autism emotion recogition dataset'\n",
    "train_dir = data_root / 'train'\n",
    "test_dir = data_root / 'test'\n",
    "models_dir = ml_root / 'models'\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_model_path = models_dir / 'best_model.keras'\n",
    "label_map_path = models_dir / 'label_map.json'\n",
    "print('train_dir =', train_dir)\n",
    "print('test_dir  =', test_dir)\n",
    "print('models_dir=', models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 32\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "CLASSES = ['Natural','joy','fear','anger','sadness','surprise']  # fixed order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets using directory structure\n",
    "assert train_dir.exists(), f'Train directory not found: {train_dir}'\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset='training',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    label_mode='int',\n",
    "    class_names=CLASSES\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    label_mode='int',\n",
    "    class_names=CLASSES\n",
    ")\n",
    "class_names = CLASSES\n",
    "print('Class names:', class_names)\n",
    "with open(label_map_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump({'classes': class_names}, f, indent=2)\n",
    "# Prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "def prep(ds):\n",
    "    return ds.map(lambda x,y: (preprocess_input(tf.cast(x, tf.float32)), y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "train_ds_p = prep(train_ds)\n",
    "val_ds_p = prep(val_ds)\n",
    "test_ds_p = None\n",
    "if test_dir.exists():\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        test_dir, image_size=IMG_SIZE, batch_size=BATCH, label_mode='int', class_names=CLASSES)\n",
    "    test_ds_p = prep(test_ds)\n",
    "    print('Test samples available')\n",
    "else:\n",
    "    print('No separate test directory; will evaluate on validation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c832eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DenseNet-121 model\n",
    "base = DenseNet121(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "base.trainable = False  # fine-tune later if needed\n",
    "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "x = preprocess_input(tf.cast(inputs, tf.float32))\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(len(CLASSES), activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f815a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(str(best_model_path), monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "hist = model.fit(train_ds_p, validation_data=val_ds_p, epochs=15, callbacks=[ckpt, early])\n",
    "# Ensure best is saved\n",
    "model.save(best_model_path)\n",
    "print('Saved best model to:', best_model_path)\n",
    "# Write BEST_MODEL_PATH.txt for the Flask app\n",
    "with open(ml_root / 'BEST_MODEL_PATH.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db249f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "eval_ds = test_ds_p or val_ds_p\n",
    "loss, acc = model.evaluate(eval_ds)\n",
    "print('Eval accuracy:', acc)\n",
    "# Classification report\n",
    "y_true, y_pred = [], []\n",
    "for bx, by in eval_ds:\n",
    "    p = model.predict(bx, verbose=0)\n",
    "    y_true.extend(by.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(p, axis=1).tolist())\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc16c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-image inference helper\n",
    "from PIL import Image\n",
    "def predict_image(path: str):\n",
    "    img = Image.open(path).convert('RGB').resize(IMG_SIZE)\n",
    "    arr = np.array(img)[None, ...]\n",
    "    arr = preprocess_input(arr.astype('float32'))\n",
    "    probs = model.predict(arr, verbose=0)[0]\n",
    "    top = int(np.argmax(probs))\n",
    "    return {\n",
    "        'emotion': CLASSES[top],\n",
    "        'confidence': float(probs[top]),\n",
    "        'allPredictions': {c: float(probs[i]) for i, c in enumerate(CLASSES)}\n",
    "    }\n",
    "# Example: replace with your image path\n",
    "# predict_image(str(train_dir / 'joy' / os.listdir(train_dir / 'joy')[0]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
